# ONLINE BANKING ANALYSIS

This project uses Apache Spark. For this project, I obtained datasets from kaggle, including those for loans, client credit cards, and transactions. We cleaned the data after downloading the datasets. Then we ran new use cases on the datasets we had obtained from Kaggle using new tools and technologies like Spark, HDFS, Hive, and many others. Apache Spark is a framework that can swiftly process huge datasets.
                            
Let me now describe the dataflow of what we did: first, we retrieved the data and then downloaded the datasets from Kaggle, storing them in database, and then importing them from MYSQL to hive by sqoop. This is how we ingested the data. Second, we processed the large datasets in hive, and then we analysed the data using PySpark in a Jupyter notebook by implementing several strategies.
                            
 ## TECHNOLOGIES USED:
 Spark SQL
 Spark
 HDFS
 Hive
                          
 ## Procedure :
 
 Utilized the historical data from kaggle.com.
 Collected 3 datasets of online transactions, loan and customer credit card.
 Implemented Spark Session to load the data into Data Frames.
 Used standalone cluster mode in spark environment to run on Spark SQL queries.
 Version control with Git/Github.

